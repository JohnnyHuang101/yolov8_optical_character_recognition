{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4872f82d-a0d0-4a3d-8b3b-783bd915807b",
   "metadata": {},
   "source": [
    "!pip install roboflow\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539cddda-0d9d-4749-959f-dbc3d015c824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt-detr-l summary: 673 layers, 32,970,476 parameters, 0 gradients, 108.3 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(673, 32970476, 0, 108.3437056)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "from ultralytics import RTDETR #transformer based yolo\n",
    "\n",
    "\n",
    "model = RTDETR(\"rtdetr-l.pt\")\n",
    "\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a212208a-2848-422f-8b25-0fb04738f714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Open-Poetry-Vision-1 to yolov8:: 100%|██████████| 171515/171515 [01:01<00:00, 2771.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Open-Poetry-Vision-1 in yolov8:: 100%|██████████| 8012/8012 [00:10<00:00, 748.89it/s] \n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"#####YourAPI KEY OK??\")\n",
    "project = rf.workspace(\"roboflow-gw7yv\").project(\"open-poetry-vision\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b434224a-0d28-41af-94a5-b662ca6436a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\jhsup\\C_Documents\\Rock-Paper-Scissors-1\\valid\\paper\\testpaper01-00_png.rf.e38ed8f1d4ed68c26430ba3d1e0c2a6a.jpg: 640x640 1 person, 426.0ms\n",
      "Speed: 4.0ms preprocess, 426.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(r'C:\\Users\\jhsup\\C_Documents\\Rock-Paper-Scissors-1\\valid\\paper\\testpaper01-00_png.rf.e38ed8f1d4ed68c26430ba3d1e0c2a6a.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddbdc480-25d1-4ff2-82b6-a8bbd902e7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "detections = results[0].boxes.data\n",
    "\n",
    "# Iterate through detections\n",
    "for box in detections:\n",
    "    x1, y1, x2, y2, confidence, class_id = box\n",
    "    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "    # Draw bounding box\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (10,10,10), 2)\n",
    "\n",
    "    # Add label\n",
    "    label = f\"Class {int(class_id)}: {confidence:.2f}\"\n",
    "    cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (10,10,10), 2)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Predictions', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43c05623-9927-4dcb-9cc4-627574014429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt-detr-l summary: 673 layers, 32,970,476 parameters, 0 gradients, 108.3 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(673, 32970476, 0, 108.3437056)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import RTDETR\n",
    "\n",
    "model = RTDETR('rtdetr-l.pt')\n",
    "model.info()# too big so i cant train it, maybe someone with a better computer whaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "924790a3-145b-4b51-b5dd-a537eed1d2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary: 225 layers, 3,019,233 parameters, 0 gradients, 8.2 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(225, 3019233, 0, 8.2393088)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(r\"C:\\Users\\jhsup\\C_Documents\\runs\\detect\\train16\\weights\\best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1dd99fa-2483-494c-99d6-992123b9e37e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2  \n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  # Or another backend like 'Qt5Agg'\n",
    "\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(r'C:\\Users\\jhsup\\C_Documents\\Open-Poetry-Vision-1\\valid\\images\\2_jpg.rf.bH0vPmTW32rtkY1g0SDd.jpg')\n",
    "# Convert BGR to RGB (OpenCV loads in BGR format)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Optional: Turn off axis\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3f84e94-3fd2-4c8f-9b4f-8451c2b9ab97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.4\n",
      "PyTorch Version: 2.5.1+cu124\n",
      "0.20.1+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "print(torch.version.cuda)\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "import torchvision\n",
    "print(torchvision.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74cd6d73-f7f7-4629-b685-c2f325075e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMS passed, indices: tensor([0, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.ops import nms\n",
    "\n",
    "boxes = torch.tensor([[0, 0, 1, 1], [0, 0, 1, 1], [1, 1, 2, 2]], dtype=torch.float32)\n",
    "scores = torch.tensor([0.9, 0.8, 0.75], dtype=torch.float32)\n",
    "iou_threshold = 0.5\n",
    "\n",
    "try:\n",
    "    keep = nms(boxes, scores, iou_threshold)\n",
    "    print(\"NMS passed, indices:\", keep)\n",
    "except NotImplementedError as e:\n",
    "    print(\"NMS failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e6586c4-6f81-4651-9cd8-8c418e04d828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.58 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.56  Python-3.12.3 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 2070, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:\\Users\\jhsup\\C_Documents\\Open-Poetry-Vision-1\\data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=4, project=None, name=train16, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train16\n",
      "Overriding model.yaml nc=80 with nc=43\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    759697  ultralytics.nn.modules.head.Detect           [43, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3,019,233 parameters, 3,019,217 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train16', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\jhsup\\C_Documents\\Open-Poetry-Vision-1\\train\\labels.cache... 2798 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2798/2798 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\jhsup\\C_Documents\\Open-Poetry-Vision-1\\valid\\labels.cache... 800 images, 0 backgrounds, 0 corrupt: 100%|██████████| 800/800 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train16\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000213, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train16\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      2.24G      2.198      5.198      1.772         39        640: 100%|██████████| 175/175 [00:33<00:00,  5.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 25/25 [00:06<00:00,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       2404     0.0133      0.694     0.0222     0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      2.23G      1.276      4.015      1.204         43        640: 100%|██████████| 175/175 [00:26<00:00,  6.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 25/25 [00:06<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       2404      0.102        0.2     0.0509     0.0325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      2.24G      1.179      3.598       1.15         37        640: 100%|██████████| 175/175 [00:27<00:00,  6.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 25/25 [00:06<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       2404      0.102      0.111     0.0757      0.053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      2.24G      1.104      3.317      1.109         46        640: 100%|██████████| 175/175 [00:26<00:00,  6.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 25/25 [00:06<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       2404       0.15      0.181      0.104     0.0746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      2.23G      1.043      3.128      1.074         34        640: 100%|██████████| 175/175 [00:26<00:00,  6.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 25/25 [00:06<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       2404      0.154      0.188       0.12      0.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      2.23G      1.009      3.007      1.059         34        640: 100%|██████████| 175/175 [00:25<00:00,  6.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 25/25 [00:06<00:00,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       2404      0.149      0.235       0.15      0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      2.23G      0.968      2.901       1.04         35        640: 100%|██████████| 175/175 [00:25<00:00,  6.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 25/25 [00:06<00:00,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       2404      0.179      0.274      0.176      0.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      2.24G      0.948      2.829      1.031         35        640: 100%|██████████| 175/175 [00:25<00:00,  6.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 25/25 [00:06<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       2404      0.147      0.301      0.197      0.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      2.23G     0.9227      2.757      1.023         49        640: 100%|██████████| 175/175 [00:26<00:00,  6.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 25/25 [00:05<00:00,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       2404      0.181      0.318      0.208      0.158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      2.23G     0.9224      2.737      1.015         33        640: 100%|██████████| 175/175 [00:25<00:00,  6.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 25/25 [00:05<00:00,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       2404      0.143      0.303      0.216      0.165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.102 hours.\n",
      "Optimizer stripped from runs\\detect\\train16\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from runs\\detect\\train16\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating runs\\detect\\train16\\weights\\best.pt...\n",
      "Ultralytics 8.3.56  Python-3.12.3 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 2070, 8192MiB)\n",
      "Model summary (fused): 168 layers, 3,014,033 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 25/25 [00:06<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       2404      0.144      0.304      0.216      0.165\n",
      "   American Typewriter         56         58      0.123      0.103     0.0832     0.0652\n",
      "           Andale Mono         42         46      0.211      0.739      0.356      0.291\n",
      "        Apple Chancery         44         46          0          0     0.0645     0.0511\n",
      "                 Arial         50         54          0          0       0.06     0.0472\n",
      "                Avenir         64         70      0.198      0.171      0.145      0.124\n",
      "           Baskerville         52         54     0.0838      0.259      0.105     0.0823\n",
      "            Big Caslon         68         70      0.099     0.0286     0.0848      0.072\n",
      "          Bradley Hand         54         58      0.458      0.655      0.463      0.354\n",
      "       Brush Script MT         74         74      0.421      0.892      0.653       0.48\n",
      "            Chalkboard         50         52          0          0     0.0936     0.0784\n",
      "         Comic Sans MS         68         72          0          0     0.0809      0.064\n",
      "           Copperplate         60         64      0.311      0.692      0.343      0.212\n",
      "               Courier         42         46      0.189      0.652      0.349      0.219\n",
      "                 Didot         56         56      0.177      0.655      0.396      0.312\n",
      "                Futura         46         50       0.15       0.64      0.273       0.21\n",
      "                Geneva         48         48     0.0375     0.0833     0.0344     0.0302\n",
      "               Georgia         72         72     0.0609     0.0833     0.0855     0.0658\n",
      "             Gill Sans         62         62          0          0     0.0544     0.0415\n",
      "             Helvetica         48         50          0          0     0.0757     0.0645\n",
      "            Herculanum         74         78      0.479      0.718      0.659      0.494\n",
      "                Impact         64         70          0          0     0.0836     0.0653\n",
      "                  Kefa         54         56          0          0     0.0443      0.033\n",
      "         Lucida Grande         48         48      0.157     0.0417     0.0923     0.0811\n",
      "              Luminari         38         38      0.122      0.316      0.131     0.0951\n",
      "           Marker Felt         64         68      0.277      0.559        0.5      0.438\n",
      "                 Menlo         36         36     0.0996      0.389      0.125      0.105\n",
      "                Monaco         34         34      0.141      0.647      0.239      0.186\n",
      "            Noteworthy         58         58       0.19      0.724      0.391       0.33\n",
      "                Optima         54         54     0.0603      0.148     0.0902     0.0701\n",
      "               PT Sans         56         60          0          0     0.0728     0.0558\n",
      "              PT Serif         68         72      0.248     0.0278      0.106     0.0818\n",
      "              Palatino         50         50      0.033       0.04     0.0805     0.0635\n",
      "               Papyrus         40         40      0.319       0.85      0.729      0.544\n",
      "             Phosphate         60         62      0.426      0.968      0.842      0.626\n",
      "              Rockwell         52         52          0          0     0.0637     0.0515\n",
      "                SF Pro         60         62     0.0856     0.0726     0.0752     0.0555\n",
      "           SignPainter         46         50      0.124       0.16     0.0879     0.0666\n",
      "                  Skia         58         58      0.337      0.351      0.247      0.165\n",
      "       Snell Roundhand         50         56      0.362      0.964      0.583      0.422\n",
      "                Tahoma         64         66      0.106      0.242     0.0851     0.0708\n",
      "       Times New Roman         46         48     0.0921      0.182     0.0935     0.0777\n",
      "          Trebuchet MS         42         44          0          0     0.0329     0.0271\n",
      "               Verdana         42         42          0          0     0.0449     0.0383\n",
      "Speed: 0.2ms preprocess, 1.7ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train16\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(data=r'C:\\Users\\jhsup\\C_Documents\\Open-Poetry-Vision-1\\data.yaml', epochs=10, imgsz=640, batch=16, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3873675b-ef09-4768-bd0e-9bd1129b6a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\jhsup\\C_Documents\\Open-Poetry-Vision-1\\test\\images\\24_jpg.rf.589cff6ef889bde7151ba3850b00df97.jpg: 640x640 1 Papyrus, 76.0ms\n",
      "Speed: 22.0ms preprocess, 76.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(r\"C:\\Users\\jhsup\\C_Documents\\Open-Poetry-Vision-1\\test\\images\\24_jpg.rf.589cff6ef889bde7151ba3850b00df97.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ac18c39-991f-448d-8d99-7d3118b383dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "result = results[0]\n",
    "\n",
    "# Assuming 'results' is your ultralytics.engine.results.Results object\n",
    "# Extract bounding boxes, confidence scores, and class IDs\n",
    "if result.boxes is not None:\n",
    "    bboxes = result.boxes.xyxy  # x_min, y_min, x_max, y_max (pixel values)\n",
    "    confs = result.boxes.conf  # Confidence scores\n",
    "    class_ids = result.boxes.cls  # Class IDs (indices)\n",
    "else:\n",
    "    bboxes, confs, class_ids = [], [], []\n",
    "\n",
    "# Extract class labels\n",
    "class_labels = result.names\n",
    "\n",
    "# Load the original image\n",
    "image = result.orig_img\n",
    "\n",
    "# Draw bounding boxes\n",
    "for i in range(len(bboxes)):\n",
    "    # Get box coordinates\n",
    "    x_min, y_min, x_max, y_max = map(int, bboxes[i])\n",
    "    conf = confs[i]\n",
    "    class_id = int(class_ids[i])\n",
    "    label = f\"{class_labels[class_id]}: {conf:.2f}\"\n",
    "\n",
    "    # Draw rectangle on the image\n",
    "    color = (255, 0, 0)  # Red for bounding boxes\n",
    "    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "\n",
    "    # Add label above the bounding box\n",
    "    cv2.putText(image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.5, color, 2)\n",
    "\n",
    "# Convert BGR to RGB for displaying with Matplotlib\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f18d2d88-b130-4785-bf4c-73ba9be76c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'American Typewriter', 1: 'Andale Mono', 2: 'Apple Chancery', 3: 'Arial', 4: 'Avenir', 5: 'Baskerville', 6: 'Big Caslon', 7: 'Bradley Hand', 8: 'Brush Script MT', 9: 'Chalkboard', 10: 'Comic Sans MS', 11: 'Copperplate', 12: 'Courier', 13: 'Didot', 14: 'Futura', 15: 'Geneva', 16: 'Georgia', 17: 'Gill Sans', 18: 'Helvetica', 19: 'Herculanum', 20: 'Impact', 21: 'Kefa', 22: 'Lucida Grande', 23: 'Luminari', 24: 'Marker Felt', 25: 'Menlo', 26: 'Monaco', 27: 'Noteworthy', 28: 'Optima', 29: 'PT Sans', 30: 'PT Serif', 31: 'Palatino', 32: 'Papyrus', 33: 'Phosphate', 34: 'Rockwell', 35: 'SF Pro', 36: 'SignPainter', 37: 'Skia', 38: 'Snell Roundhand', 39: 'Tahoma', 40: 'Times New Roman', 41: 'Trebuchet MS', 42: 'Verdana'}\n",
       " obb: None\n",
       " orig_img: array([[[ 80,  62,  61],\n",
       "         [ 80,  62,  61],\n",
       "         [ 80,  62,  61],\n",
       "         ...,\n",
       "         [ 85,  39,  38],\n",
       "         [ 85,  39,  38],\n",
       "         [ 85,  39,  38]],\n",
       " \n",
       "        [[ 81,  63,  62],\n",
       "         [ 81,  63,  62],\n",
       "         [ 81,  63,  62],\n",
       "         ...,\n",
       "         [ 85,  39,  38],\n",
       "         [ 85,  39,  38],\n",
       "         [ 85,  39,  38]],\n",
       " \n",
       "        [[ 83,  65,  64],\n",
       "         [ 83,  65,  64],\n",
       "         [ 84,  66,  65],\n",
       "         ...,\n",
       "         [ 83,  39,  38],\n",
       "         [ 83,  39,  38],\n",
       "         [ 83,  39,  38]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  7,  14,  77],\n",
       "         [255,   0,   0],\n",
       "         [255,   0,   0],\n",
       "         ...,\n",
       "         [ 23,  30,  57],\n",
       "         [ 26,  33,  60],\n",
       "         [ 25,  32,  59]],\n",
       " \n",
       "        [[ 15,  24,  62],\n",
       "         [255,   0,   0],\n",
       "         [255,   0,   0],\n",
       "         ...,\n",
       "         [ 23,  30,  57],\n",
       "         [ 27,  34,  61],\n",
       "         [ 28,  35,  62]],\n",
       " \n",
       "        [[ 20,  29,  56],\n",
       "         [255,   0,   0],\n",
       "         [255,   0,   0],\n",
       "         ...,\n",
       "         [ 22,  29,  56],\n",
       "         [ 26,  33,  60],\n",
       "         [ 26,  33,  60]]], dtype=uint8)\n",
       " orig_shape: (512, 512)\n",
       " path: 'C:\\\\Users\\\\jhsup\\\\C_Documents\\\\Open-Poetry-Vision-1\\\\test\\\\images\\\\341_jpg.rf.k5mHGkn3SGcECFC9PIWW.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\train162'\n",
       " speed: {'preprocess': 4.982233047485352, 'inference': 23.55051040649414, 'postprocess': 1.9955635070800781}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022c148-533e-49d9-ba1c-b6d1429b322d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
